import torch
from torch import nn
from transformers import BertModel, BertTokenizer
import spacy
import os
import warnings

# UyarÄ±larÄ± gizle
warnings.filterwarnings("ignore")

# --- CONFIGURATION ---
MODEL_NAME = 'dbmdz/bert-base-turkish-cased'
MAX_LEN = 128
CLASS_NAMES = ['Negative ğŸ˜¡', 'Neutral ğŸ˜', 'Positive ğŸ˜ƒ']


# --- 1. MODEL ARCHITECTURE ---
class SentimentClassifier(nn.Module):
    def __init__(self, n_classes):
        super(SentimentClassifier, self).__init__()
        self.bert = BertModel.from_pretrained(MODEL_NAME)
        self.drop = nn.Dropout(p=0.3)
        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        output = self.drop(pooled_output)
        return self.out(output)


# --- 2. LOADERS ---
def load_resources():
    print("â³ Loading AI Models (BERT + spaCy)... Please wait.")

    # A. Load Sentiment Model (BERT)
    device = torch.device("cpu")
    model = SentimentClassifier(n_classes=3)

    # Path handling
    base_path = os.path.dirname(os.path.dirname(__file__))
    model_path = os.path.join(base_path, 'models', 'best_model_state.bin')

    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found at: {model_path}")

    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()

    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)

    # B. Load Aspect Extractor (spaCy - Turkish)
    try:
        nlp = spacy.load("tr_core_news_md")  # Medium (Daha zeki)
    except OSError:
        try:
            nlp = spacy.load("tr_core_news_tr")  # Small (Yedek)
        except OSError:
            print("âŒ ERROR: Turkish spaCy model not found.")
            exit()

    print("âœ… All systems ready!")
    return model, tokenizer, nlp, device


# --- 3. IMPROVED ASPECT EXTRACTOR (STRICT FILTER) ---
def extract_aspects(nlp, text):
    doc = nlp(str(text))
    aspects = []

    blacklist = {
        'ben', 'sen', 'o', 'biz', 'siz', 'onlar', 'bu', 'ÅŸu', 'kim', 'ne', 'biri', 'birisi',
        've', 'ile', 'ama', 'fakat', 'lakin', 'veya', 'hem', 'hemde', 'da', 'de', 'ki',
        'gibi', 'kadar', 'diye', 'iÃ§in', 'Ã¼zere', 'yÃ¼zden', 'nedeniyle', 'dolayÄ±',
        'bence', 'zaten', 'artÄ±k', 'bile', 'sadece', 'daha', 'Ã§ok', 'az', 'en', 'pek',
        'gÃ¼n', 'zaman', 'saat', 'yÄ±l', 'hafta', 'bugÃ¼n', 'yarÄ±n', 'dÃ¼n', 'sonra', 'Ã¶nce',
        'ÅŸey', 'konu', 'taraf', 'kÄ±sÄ±m', 'bÃ¶lÃ¼m', 'yer', 'kez', 'kere', 'sefer',
        'lazÄ±m', 'gerek', 'var', 'yok', 'tane', 'adet',
        'iyi', 'kÃ¶tÃ¼', 'gÃ¼zel', 'Ã§irkin', 'fena', 'berbat', 'harika', 'muhteÅŸem',
        'bÃ¼yÃ¼k', 'kÃ¼Ã§Ã¼k', 'uzun', 'kÄ±sa', 'eski', 'yeni', 'zor', 'kolay', 'bozuk', 'saÄŸlam'
    }

    for token in doc:
        # 1. Kelimenin kÃ¶kÃ¼nÃ¼ (lemma) ve kÃ¼Ã§Ã¼k halini al
        lemma = token.lemma_.lower()
        text_lower = token.text.lower()

        # 2. Kural: Sadece Ä°SÄ°M (NOUN) veya Ã–ZEL Ä°SÄ°M (PROPN) olsun
        if token.pos_ not in ["NOUN", "PROPN"]:
            continue

        if token.is_stop or token.is_punct:
            continue


        if lemma in blacklist or text_lower in blacklist:
            continue

        # 5. Kural: Ã‡ok kÄ±sa kelimeleri at
        if len(text_lower) < 3:
            continue

        # Her ÅŸeyi geÃ§tiyse ekle
        aspects.append(token.text)

    return list(set(aspects))


def predict_sentiment(model, tokenizer, device, text, aspect):
    text_lower = text.lower()
    if "ne " in text_lower and " ne " in text_lower:
        return "Neutral ğŸ˜", 1.0
    # ----------------------------------------------------

    encoded = tokenizer.encode_plus(
        text, aspect, max_length=MAX_LEN, add_special_tokens=True,
        return_token_type_ids=False, padding='max_length',
        truncation=True, return_attention_mask=True, return_tensors='pt'
    )
    input_ids = encoded['input_ids'].to(device)
    attention_mask = encoded['attention_mask'].to(device)

    with torch.no_grad():
        output = model(input_ids, attention_mask)
        probs = torch.nn.functional.softmax(output, dim=1)
        _, prediction = torch.max(output, dim=1)
        conf = torch.max(probs).item()

    return CLASS_NAMES[prediction], conf


# --- MAIN APP LOOP ---
if __name__ == "__main__":
    model, tokenizer, nlp, device = load_resources()

    print("\n" + "=" * 60)
    print("ğŸ¤– AUTOMATIC ASPECT-BASED SENTIMENT ANALYSIS (STRICT MODE)")
    print("Type a sentence, and I will find the topics and judge them.")
    print("Type 'q' to quit.")
    print("=" * 60)

    while True:
        sentence = input("\nğŸ“ Enter a sentence: ")
        if sentence.lower() == 'q':
            print("Goodbye! ğŸ‘‹")
            break

        found_aspects = extract_aspects(nlp, sentence)

        if not found_aspects:
            print("âš ï¸ No specific aspects found in this sentence.")
            continue

        print(f"ğŸ” Detected Aspects: {found_aspects}")
        print("-" * 40)

        for aspect in found_aspects:
            sentiment, conf = predict_sentiment(model, tokenizer, device, sentence, aspect)
            print(f"ğŸ‘‰ {aspect.ljust(15)} : {sentiment} (Confidence: {conf * 100:.1f}%)")